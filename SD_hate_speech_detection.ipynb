{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Toxicity</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56740</th>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56741</th>\n",
       "      <td>1</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56742</th>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56743</th>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56744</th>\n",
       "      <td>0</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56745 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Toxicity                                              Tweet\n",
       "0             0   @user when a father is dysfunctional and is s...\n",
       "1             0  @user @user thanks for #lyft credit i can't us...\n",
       "2             0                                bihday your majesty\n",
       "3             0  #model   i love u take with u all the time in ...\n",
       "4             0             factsguide: society now    #motivation\n",
       "...         ...                                                ...\n",
       "56740         1  you's a muthaf***in lie &#8220;@LifeAsKing: @2...\n",
       "56741         1  you've gone and broke the wrong heart baby, an...\n",
       "56742         1  young buck wanna eat!!.. dat nigguh like I ain...\n",
       "56743         1              youu got wild bitches tellin you lies\n",
       "56744         0  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...\n",
       "\n",
       "[56745 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('HateSpeechDataset.csv',sep=',')\n",
    "col_names = ['Toxicity', 'Tweet']\n",
    "dataset.columns=col_names\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>56745.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.425641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.494444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Toxicity\n",
       "count  56745.000000\n",
       "mean       0.425641\n",
       "std        0.494444\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        1.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Toxicity', ylabel='count'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(x='Toxicity', data= dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    32592\n",
       "1    24153\n",
       "Name: Toxicity, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.Toxicity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", '@user']\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english') + ['@user']\n",
    "print(stop_words)\n",
    "vectorizer = TfidfVectorizer(use_idf=True, lowercase=True, strip_accents='ascii', stop_words=stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.Tweet\n",
    "y = dataset.Toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['user'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "X = vectorizer.fit_transform(dataset.Tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.20, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Knn algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    " \n",
    "knn.fit(X_train, y_train)\n",
    " \n",
    "# Predict on dataset which model has not seen before\n",
    "predict_Knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5530303155733634"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, predict_Knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.622169354128117\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, predict_Knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6523   42]\n",
      " [4246  538]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predict_Knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.99      0.75      6565\n",
      "           1       0.93      0.11      0.20      4784\n",
      "\n",
      "    accuracy                           0.62     11349\n",
      "   macro avg       0.77      0.55      0.48     11349\n",
      "weighted avg       0.74      0.62      0.52     11349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predict_Knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting By Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "review_1 = np.array([\"It was a good movie. I enjoyed watching the movie a lot!!\"])\n",
    "\n",
    "review_1 = vectorizer.transform(review_1)\n",
    "\n",
    "print(knn.predict(review_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "review_2 = np.array([\"Shut up!! you idiot\"])\n",
    "review_2 = vectorizer.transform(review_2)\n",
    "\n",
    "print(knn.predict(review_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "review_3 = np.array([\"You rascal!! you idiot\"])\n",
    "review_3 = vectorizer.transform(review_3)\n",
    "\n",
    "print(knn.predict(review_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Naive Bayes algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_model = naive_bayes.MultinomialNB()\n",
    "NB_model.fit(X_train, y_train)\n",
    "predict_NB = NB_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9180612354713732"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, predict_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.920521631861838\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, predict_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6130  435]\n",
      " [ 467 4317]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predict_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      6565\n",
      "           1       0.91      0.90      0.91      4784\n",
      "\n",
      "    accuracy                           0.92     11349\n",
      "   macro avg       0.92      0.92      0.92     11349\n",
      "weighted avg       0.92      0.92      0.92     11349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predict_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting By Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "review_4 = np.array([\"It was a good food. I liked it!!\"])\n",
    "\n",
    "review_4 = vectorizer.transform(review_4)\n",
    "\n",
    "print(NB_model.predict(review_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "review_5 = np.array([\"shut up!! you crazy\"])\n",
    "\n",
    "review_5 = vectorizer.transform(review_5)\n",
    "\n",
    "print(NB_model.predict(review_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_R = LogisticRegression(random_state = 0)\n",
    "logistic_R.fit(X_train, y_train)\n",
    "\n",
    "predict_LR= logistic_R.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9301129590383788"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, predict_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9373513084853291\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, predict_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6409  156]\n",
      " [ 555 4229]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predict_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      6565\n",
      "           1       0.96      0.88      0.92      4784\n",
      "\n",
      "    accuracy                           0.94     11349\n",
      "   macro avg       0.94      0.93      0.93     11349\n",
      "weighted avg       0.94      0.94      0.94     11349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predict_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting by Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "review_6 = np.array([\"This place has a nice ambience and good food!!\"])\n",
    "\n",
    "review_6 = vectorizer.transform(review_6)\n",
    "\n",
    "print(logistic_R.predict(review_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "review_7 = np.array([\"You idiote! shut up\"])\n",
    "\n",
    "review_7 = vectorizer.transform(review_7)\n",
    "\n",
    "print(logistic_R.predict(review_7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing SVM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm.SVC(kernel=\"linear\")\n",
    "svm_model.fit(X_train, y_train)\n",
    "predict_svm = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9425680486108812"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, predict_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9476605868358445\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, predict_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6401  164]\n",
      " [ 430 4354]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predict_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      6565\n",
      "           1       0.96      0.91      0.94      4784\n",
      "\n",
      "    accuracy                           0.95     11349\n",
      "   macro avg       0.95      0.94      0.95     11349\n",
      "weighted avg       0.95      0.95      0.95     11349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predict_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting by SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "review_8 = np.array([\"You are such a good person!\"])\n",
    "\n",
    "review_8 = vectorizer.transform(review_8)\n",
    "\n",
    "print(svm_model.predict(review_8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "review_9 = np.array([\"You crazy! shut up your mouth\"])\n",
    "\n",
    "review_9 = vectorizer.transform(review_9)\n",
    "\n",
    "print(logistic_R.predict(review_9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
